# AI服务设计方案

## 1. 总体设计

### 核心原则

* **事实包驱动**：AI不直接访问数据库，只基于后端生成的"事实包"进行分析

* **结构化输出**：AI输出结构化JSON，后端渲染为Markdown

* **数据校验**：所有数值必须来自事实包，确保报告准确性

* **缓存策略**：实现多层缓存，避免GitHub API限流

### 技术栈

* 后端框架：FastAPI

* LLM集成：MaxKB

* 数据存储：PostgreSQL（现有）

* 缓存：Redis（建议新增）

## 2. 模块划分与文件结构

```
app/
  services/
    ai_service/
      __init__.py
      llm_client.py          # 调用MaxKB/ECNU模型的统一客户端
      report_router.py       # 统一入口：generate_report(module, params)
      facts/
        health_facts.py      # 从health_overview_daily提取事实
        newcomer_facts.py    # 从repo_catalog/repo_issues/repo_docs提取事实
        trend_facts.py       # 从health_overview_daily提取时序事实
      templates/
        system_prompt.txt    # 通用系统提示
        health_prompt.txt    # 健康体检提示
        newcomer_prompt.txt  # 开源新人提示
        trend_prompt.txt     # 趋势监控提示
      validators/
        schema.py            # Pydantic: ReportJSON schema
        evidence_check.py    # 校验：报告引用的数字是否存在于facts
      render/
        markdown.py          # JSON->Markdown渲染
      cache.py               # 缓存管理
```

## 3. 核心功能实现

### 3.1 LLM客户端

* 实现统一的LLM调用接口，支持MaxKB和ECNU模型

* 处理模型响应，确保输出符合JSON格式

* 实现重试机制和错误处理

### 3.2 事实提取器

* **健康体检事实提取**：

  * 从health\_overview\_daily获取最新数据和历史窗口

  * 提取五维评分和关键支撑指标

  * 计算同领域对标分位数

* **开源新人事实提取**：

  * 基于domain/stack/time\_per\_week/keywords输入

  * 提取Top推荐repo列表，包含fit\_score/readiness\_score/difficulty

  * 提取readiness分项证据：响应性、活跃度、任务供给、入职文档

  * 建立在已经抓取的 `repo_catalog + repo_issues + repo_docs` 上

* **趋势监控事实提取**：

  * 从health\_overview\_daily获取时间序列数据

  * 执行统计检测：环比/同比、3-sigma异常点、趋势方向

  * 评估数据质量：缺失率、点数不足

### 3.3 报告生成流程

1. 接收API请求，验证参数
2. 检查缓存，命中则直接返回
3. 提取事实包（facts）
4. 构建提示词，调用LLM
5. 验证LLM输出的JSON结构
6. 校验报告中的数值是否来自事实包
7. 渲染JSON为Markdown
8. 缓存结果，返回响应

### 3.4 报告格式

#### 健康体检报告

* **执行摘要**：3条亮点/短板/最重要行动

* **五维解读**：每维=状态+证据指标+影响

* **根因线索**：例如backlog高→解释issue\_age\_h、first\_response

* **行动建议**：P0/P1/P2，每条绑定监控指标

* **数据质量**：字段缺失/窗口不足提示

#### 开源新人报告

* **推荐仓库**：Top 1仓库的fit/readiness/趋势/难度

* **推荐理由**：每条理由绑定证据（例如首响≈8h、good first issue 10条）

* **新手任务建议**：3条最适合的issue

* **可执行贡献路径**：步骤+命令

* **风险提示/避坑**：如"CI复杂/仓库巨大/文档缺失→建议先做docs类任务"

#### 趋势监控报告

* **Identify**：总体趋势一句话+3个关键变化

* **Diagnosis**：指标异常/稳定情况

* **Need Data**：缺什么数据才可以更准

* **Improvements**：绑定可执行动作+监控指标

* **Monitor**：继续监控的指标列表+建议阈值

## 4. API设计

### 4.1 健康体检报告

* **Endpoint**：`POST /ai/report/health`

* **Request**：`{"repo_full_name": "microsoft/vscode", "time_window_days": 30}`

* **Response**：`{"report_markdown": "...", "report_json": {...}, "meta": {...}}`

### 4.2 开源新人报告

* **Endpoint**：`POST /ai/report/newcomer`

* **Request**：`{"domain": "ai_ml", "stack": "python", "time_per_week": "1-2h", "keywords": "rag docs", "top_n": 3}`

* **Response**：`{"report_markdown": "...", "report_json": {...}, "meta": {...}}`

### 4.3 趋势监控报告

* **Endpoint**：`POST /ai/report/trend`

* **Request**：`{"repo_full_name": "chaoss/augur", "time_window_days": 180, "metrics": ["activity", "first_response", "bus_factor", "scorecard"]}`

* **Response**：`{"report_markdown": "...", "report_json": {...}, "meta": {...}}`

## 5. 缓存策略

### 5.1 缓存层级

* **repo\_issues缓存**：TTL 1-6小时

* **repo\_docs缓存**：TTL 24小时

* **ai\_reports缓存**：同参数请求TTL 30-60分钟

### 5.2 缓存键设计

* 格式：`module + repo + time_window + input_hash`

* 确保相同参数的请求能命中缓存

## 6. 渲染与格式化

### 6.1 统一格式化规则

* 百分比：保留1位小数（49.1%）

* 小时：保留1位小数（7.3h）

* 分数：保留0-2位小数（健康分整数更直观）

* 空值：显示`--`并在warnings中说明原因

### 6.2 Markdown渲染

* 使用统一的Markdown模板

* 支持不同板块的特定格式需求

* 确保渲染结果与前端展示兼容

## 7. 集成与部署

### 7.1 集成点

* 与现有健康指标服务集成

* 与现有开源新人推荐服务集成

* 与现有趋势分析服务集成

* 在主API路由中添加AI服务端点

### 7.2 部署建议

* 添加Redis作为缓存层

* 配置LLM服务的环境变量

* 更新requirements.txt，添加必要依赖

## 8. 监控与维护

### 8.1 日志记录

* 记录LLM调用耗时和成功率

* 记录缓存命中率

* 记录数据质量问题

### 8.2 错误处理

* 实现优雅的错误降级

* 当LLM服务不可用时返回基于事实的基本报告

* 当数据不足时明确说明限制

## 9. 后续优化方向

* 实现多模型对比，选择最优模型

* 开发报告质量评估机制

* 支持用户自定义报告模板

* 实现报告版本控制和历史追踪

